# FaceMoCap: Robust Label Matching via Deep Point-wise Classification

## 1. Introduction

### 1.1 Problem Statement

Facial motion capture systems generate clouds of 3D markers tracking the movement of a subject's face. A critical step in processing this data is **Label Matching**: assigning semantic identities (e.g., "Nose Tip", "Left Eye Outer", "Chin") to an unordered set of 3D points.

The raw data consists of sequential point clouds $X \in \mathbb{R}^{N \times 3}$, where $N \approx 105$. The input data presents three main challenges:

1. **Permutation Ambiguity:** The points are unordered; the index $i$ in the array does not correspond to a fixed semantic label.
2. **Global Misalignment:** The subject may be positioned anywhere in space with arbitrary rotation (e.g., facing "Y-up" vs "Z-up", or rotated 180°).
3. **Noise and Occlusions:** Markers may be missing (NaNs) or jittered due to tracking errors.

### 1.2 General Strategy

We employ a **hybrid Geometric-Deep Learning approach**.

* **Geometry** provides the global reference frame. We construct a "Canonical Mean Shape" and align all incoming data to this standardized space.
* **Deep Learning** provides the local feature extraction. A point-wise Multi-Layer Perceptron (MLP) classifies each point based on its $(x, y, z)$ coordinates in the canonical space.
* **Combinatorial Optimization** ensures global consistency. We use the Hungarian (or Kabsh) Algorithm to enforce a one-to-one mapping between observed points and semantic labels.

---

## 2. Methodology

### 2.1 Training Phase: Canonical Space & Classifier

**A. Generalized Procrustes Analysis (GPA)**
First, we establish a global reference frame (Canonical Space) using the initial frames of the training dataset. Let $S_1, \dots, S_M$ be the training shapes. We iteratively solve for a mean shape $\bar{S}$ and rigid transformations $(R_i, t_i)$ that minimize the alignment error:

The resulting $\bar{S}$ defines the **Canonical Centroids** $\mathcal{C} = \{c_1, \dots, c_K\}$, where $c_j$ is the expected coordinate of label $j$.

**B. Deep Point-wise Classifier**
We train a neural network $f_\theta$ (a 4-layer MLP) to predict the label probability of a single 3D point.

* **Input:** A single point $p \in \mathbb{R}^3$, aligned to canonical space and standardized.
* **Output:** A probability vector over $K=105$ classes.

Training samples are generated by taking valid points from training files, applying the known Ground Truth alignment to the canonical space, and optimizing the **Cross-Entropy Loss**.

### 2.2 Evaluation Phase: Robust Inference

During inference, ground truth labels are unavailable, making standard alignment (Kabsch) impossible. We use a robust "Blind Alignment" pipeline.

**Step 1: Robust Multi-Start Alignment (Geometry)**
To solve catastrophic alignment failures (e.g., subject facing backwards), we employ a grid-search initialization before fine-tuning.

1. **Center** the test cloud $X$.
2. **Grid Search:** Test rotations $R \in \{0^\circ, 90^\circ, 180^\circ, 270^\circ\}$ around principal axes.
3. **Selection:** Choose rotation $R^*$ that minimizes the mean distance to the nearest neighbor in the Canonical Centroids $\mathcal{C}$.
4. **Fine-Tuning:** Run Iterative Closest Point (ICP) starting from $R^*$ to achieve precise alignment.

**Step 2: Probability Matrix Construction**
For the aligned test cloud $X'$, we compute the cost matrix $M \in \mathbb{R}^{N \times K}$, where entries represent the negative log-probability that observed point $i$ is label $j$:

**Step 3: Hungarian Matching**
We solve the Linear Assignment Problem to find the optimal permutation $\pi$ that minimizes total cost (maximizes total likelihood):

---

## 3. Results

The robust methodology was evaluated on a test set of **34 subjects**. The Multi-Start Alignment successfully resolved previous orientation issues, eliminating all "Bad" and "Terrible" cases.

### 3.1 Performance Summary

* **Total Test Cases:** 34
* **Success Rate:** 100% (Acc > 87%)
* **Excellent (Acc > 95%):** 26 cases (76%)
* **Regular (80% ≤ Acc < 95%):** 8 cases (24%)
* **Failure (Acc < 80%):** 0 cases



### 3.2 Detailed Statistics

| Metric | Excellent Cases (n=26) | Regular Cases (n=8) |
| --- | --- | --- |
| **Mean Accuracy** | **98.60%** | **89.70%** |
| **Median Accuracy** | 99.00% | 89.07% |
| **Mean Missing Points** | 4.7 / 105 | 11.2 / 105 |
| **Spatial Consistency** | High $(\sigma \approx 0.70)$ | Moderate $(\sigma \approx 0.72)$ |

**Observation:** The drop in performance for "Regular" cases is strongly correlated with missing data (Mean 11.2 missing points vs 4.7 in Excellent). When significant landmarks are missing, geometric alignment becomes less constrained, leading to minor drifts that affect classification.

### 3.3 Visual Examples

**Excellent Case (Accuracy: 100%)**
*Subject aligned perfectly. Predicted labels (right) match Ground Truth (left).*

**Regular Case (Accuracy: ~89%)**
*Note the sparse points (grey) indicating missing data, which complicates the Hungarian (or Kabsch) matching.*

---

## 4. Usage

The code can be run in **evaluation-only mode** using the pre-trained model and the robust alignment pipeline.

```bash
python dl_label_matching_real_facemocap_v4.py \
    --root "/path/to/Data_FaceMoCap/Sujets_Sains" \
    --train_ratio 0.9 \
    --seed 0 \
    --eval_only \
    --save_model "models/facemocap_hardalign_model.pth" \
    --report "analysis_report.txt"

```

### Requirements

* Python 3.8+
* PyTorch
* NumPy, Pandas, SciPy
* Matplotlib (for visualization)
